{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:19.253413Z",
     "start_time": "2024-06-05T20:33:19.159071Z"
    }
   },
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:19.537273Z",
     "start_time": "2024-06-05T20:33:19.513221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "mlflow.pytorch.autolog()"
   ],
   "id": "3d1e7f3f3c1a481d",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Model Extraction",
   "id": "38068f2ec570967a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:21.198798Z",
     "start_time": "2024-06-05T20:33:19.840598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = \"bert-base-uncased\"\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")\n"
   ],
   "id": "c4d7d8084917f9f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:22.521126Z",
     "start_time": "2024-06-05T20:33:21.202960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_dict = dict({'positive': 1, 'negative': 0})\n",
    "data = pd.read_csv(\"data/imdb_dataset.csv\")\n",
    "data['sentiment'] = data['sentiment'].map(label_dict)\n",
    "data = data[:1000]"
   ],
   "id": "edea2b3e7bef4378",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Train Test Split",
   "id": "f10b1a3aa4783e34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:22.542413Z",
     "start_time": "2024-06-05T20:33:22.523009Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['sentiment']), data['sentiment'], test_size=0.2, random_state=42)",
   "id": "7f4367e062f342df",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Data Preparation",
   "id": "6db195855e38fa5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:22.715862Z",
     "start_time": "2024-06-05T20:33:22.544471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ],
   "id": "4ef8018af5b34343",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:22.986485Z",
     "start_time": "2024-06-05T20:33:22.716665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    list(X_train.review.values),\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    list(X_test.review.values),\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    "\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(y_train.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(y_test.values)"
   ],
   "id": "3ef9f8d5a6b36f7d",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:22.990308Z",
     "start_time": "2024-06-05T20:33:22.987249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_train = TensorDataset(input_ids_train,\n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val,\n",
    "                            attention_masks_val,\n",
    "                            labels_val)"
   ],
   "id": "24d9476ba801ccce",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Creating Data Loaders\n",
   "id": "909ac272ee36da2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:22.996649Z",
     "start_time": "2024-06-05T20:33:22.991011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "id": "ec653e49c588d906",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Setting up Optimizer",
   "id": "4739a8a219ffb168"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:23.027835Z",
     "start_time": "2024-06-05T20:33:22.997593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-5,\n",
    "    eps = 1e-8\n",
    ")"
   ],
   "id": "37ca60117d7e6d8d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuriivoievidka/UCU/MLops/HW2/SentimentAnalysisService/venv/lib/python3.9/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:23.057412Z",
     "start_time": "2024-06-05T20:33:23.028988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps = len(dataloader_train)*epochs\n",
    ")"
   ],
   "id": "da080ad2f8288d0a",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Defining our Performance Metrics",
   "id": "55cf57d29352ddad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:23.062038Z",
     "start_time": "2024-06-05T20:33:23.059273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ],
   "id": "c7ac29e8c92caf9d",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:23.066641Z",
     "start_time": "2024-06-05T20:33:23.062838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "    \n",
    "    print(y_preds, y_true)\n",
    "    \n",
    "    return y_preds[0]/ y_true[0], y_preds[1] / y_true[1]"
   ],
   "id": "cd961bafc25d7da2",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 8. Creating our Training Loop",
   "id": "8fb6a2712c8430fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:23.111208Z",
     "start_time": "2024-06-05T20:33:23.096096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ],
   "id": "ea8cb005e492f789",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:23.457827Z",
     "start_time": "2024-06-05T20:33:23.451509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ],
   "id": "9eeb248b733275da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:23.711217Z",
     "start_time": "2024-06-05T20:33:23.704950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in tqdm(dataloader_val):\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                  }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals"
   ],
   "id": "d2551b17fb1637f4",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:33:24.119985Z",
     "start_time": "2024-06-05T20:33:24.110908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc=f'Epoch {epoch}',\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2]\n",
    "            }\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': f'{loss.item() / len(batch):.3f}'})\n",
    "\n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "        accuracy = accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_f1\": val_f1,\n",
    "            \"accuracy_positive\": accuracy[0],\n",
    "            \"accuracy_negative\": accuracy[1]\n",
    "        })"
   ],
   "id": "a7da61cdaa2509fd",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-05T20:33:24.623326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "expr_name = \"/Users/yuriivoievidka/bert-base-uncased\"\n",
    "s3_bucket = \"s3://model-storage-05062024\"\n",
    "mlflow.set_experiment(expr_name)\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.set_tag(\"Training Info\", \"Training BERT on IMDB Dataset\")\n",
    "    mlflow.log_param(\"model_name\", 'bert-base-uncased')\n",
    "    mlflow.log_param(\"num_train_epochs\", epochs)\n",
    "    mlflow.log_param(\"per_device_train_batch_size\", batch_size)\n",
    "\n",
    "    train(model)\n",
    "\n",
    "    model_name = \"BERT_IMDB_Classification\"\n",
    "    result = mlflow.register_model(\n",
    "        \"runs:/{}/model\".format(mlflow.active_run().info.run_id),\n",
    "        model_name\n",
    "    )\n",
    "\n",
    "    print(run.info)\n",
    "\n",
    "    artifact_path = f\"runs:/{run.info.experiment_id}/{run.info.run_id}/artifacts/bert-base-uncased\"\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "    print(mlflow.get_artifact_uri(artifact_path))\n",
    "\n",
    "mlflow.end_run()"
   ],
   "id": "af029c53a2a2708c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ef1680aee744cfc94a535406b9c9b96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "run.info",
   "id": "34a3c96a952524d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.pytorch.log_model(model, artifact_path)\n",
    "print(mlflow.get_artifact_uri(artifact_path))\n"
   ],
   "id": "366f19f022e30e6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "mlflow.end_run()\n",
   "id": "914c7d261c071706",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f6c8b5505f3b95a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
